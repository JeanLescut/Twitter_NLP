{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlescutmuller/.local/lib/python3.7/site-packages/pandas/compat/_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412369115575160836\n",
      "1419276389878882308\n",
      "(26895, 6)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('./data/tweets_raw/v3/df.pkl')\n",
    "print(df['id'].min())\n",
    "print(df['id'].max())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Topic example (https://github.com/MaartenGr/BERTopic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bertopic import BERTopic\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    " \n",
    "# docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "# topic_model = BERTopic()\n",
    "# topics, _ = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Labeling before Semi-supervised learning :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_label_conf = {\n",
    "    \n",
    "    ##############################\n",
    "    # Industrial Applications :\n",
    "    ##############################\n",
    "    \"application : industry (general)\":{\"industry\":1, \"enterprise\":1, \"business\":1},\n",
    "    \"application : covid19\":{\"covid\":20,\"coronavirus\":20,\"delta variant\":10,\"delta\": 3,\"vaccine\":1},\n",
    "    \"application : cybersecurity\":{\n",
    "        \"cybersecurity\": 10, \"cyber-security\": 10, \"malware\":5,\n",
    "        \"security\":1, \"cyber\":1, \"hack\":1},\n",
    "    \"application : robotics\":{\"robotic\":8,\"robot\":3},\n",
    "    \"application : finance\":{\"fintech\":10,\"financ\":4,\"bank\":4,\"economic\":4},\n",
    "    \"application : climatology\":{\n",
    "        \"weather forecast\":10,\"climato\": 9, \n",
    "        \"climate\":4,\"weather\":4,\"wind\":3,\"temperature\":3,\"atmosphere\":3,\"meteo\":3},\n",
    "    \"application : healthcare\":{\n",
    "        \"healthcare\":10,\n",
    "        \"clinical\":5,\"medical\":4,\"medicine\":4,\"patients\":3,\n",
    "        \"doctor\":2, # can be a phd...\n",
    "        \"surgical\":2,\"surgery\":2,\"care\":1},\n",
    "    \"application : marketing\":{\"marketing\":5,\"customer analy\":5,\"customers analy\":5,\"crm\":5},\n",
    "    \"application : astronomy\":{\n",
    "        \"astronomy\":8,\"universe\":8,\"star\":1 # can be a rockstar..\n",
    "        },\n",
    "    \"application : nuclear\":{\"nuclear\":8,\"nitrogen\":8,\"atomic\":5},\n",
    "    \"application : cooking\":{\"cooking\":5,\"recipe\":4,\"food\":5},\n",
    "    \"application : media & politics\":{\n",
    "        \"trump\":10,\"biden\":10,\"federal\":10,\"media\":6,\"election\":6,\"president\":6,\"liberal\":6,\n",
    "        \"politic\":5,\"conservat\":4,\"news\":4,\"positive\":1,\"negative\":1},\n",
    "    \"afghanistan\":{\"afghanistan\":5,\"taliban\":5},\n",
    "    \n",
    "    ##############################\n",
    "    # Technics :\n",
    "    ##############################\n",
    "    \"cloud technologies\":{\n",
    "        \"amazon web service\":6,\" aws \":6, \"google cloud\": 6, \" gcp \":4,\"azure\":5,\"cloud\":4},\n",
    "    \"implementation & tools\":{\n",
    "         \"keras\":6,\"pytorch\":6,\"tensorflow\":6,\"sklearn\":4,\n",
    "        \"spark\":4,\"pandas\":3,\"python\":2,\"rstudio\": 2,\" r \": 2,\n",
    "        \"matlab\":2,\"matplotlib\":2,\" sas \":2,\n",
    "        \"javascript\":2,\"framework\":1,\n",
    "        'language': 2, 'code': 1, 'coding': 1},\n",
    "    \"maths\":{\n",
    "        \"matrices\":5,\"matrix\":5,'gradient': 5,\n",
    "        'derivative': 4,'laplace':4,'lagrange':4,'poisson':4,'distribution': 2,\n",
    "        \"product\":1, # Can be a product that you buy...\n",
    "   },\n",
    "   \"devops\":{\"devops\":5,\"mlops\":5,\"dataops\":5,\"docker\":5,\"deploy\":5},\n",
    "    \n",
    "    ##############################\n",
    "    # Data-Science branch :\n",
    "    ##############################\n",
    "    \"dataviz\":{\"dataviz\":3,\" plot\":2, \"dashboard\":2, \"vizualize\":1},\n",
    "    \"deep learning\":{\n",
    "        \"neural network\":10,\" deep learn\": 9,\" deep \":1,\" rnn \":7,\" lstm \":6,\n",
    "        \"neural\":5,\"convolutional\":5,\"transformer\":5},\n",
    "    \"machine learning\":{\" ml \":1,\"machine learning\":1},\n",
    "    \"AI\":{\"artificial intelligence\":1,\" ai \":1, 'artificialintelligence': 1},\n",
    "    \n",
    "    ##############################\n",
    "    # Academic/Training\n",
    "    ##############################\n",
    "    \"university/school\":{\n",
    "        \"scholarship\":8,\" phd \":8,\"universit\":5,\"school\":5,\"student\":5,\n",
    "        \"academic\":3,\"fellowship\":3, \"professor\":3,\n",
    "        \"graduate\":2,\"degree\":2,'course':2,'diploma':2,'cursus':2,\"certificat\":2,\n",
    "        \"skill\":1,'apply':1,\"lecture\": 1},\n",
    "   \"training\":{\n",
    "       \"tuto\":5,\"handson\":3,\"hands on\":3,\n",
    "       \"learn\":2,\"bootcamp\":2,\n",
    "       \"training\":1,\"skill\":1,\n",
    "       'machine learn': -2 # Because of 'learn' up above\n",
    "   },\n",
    "   \"book\":{\"book\":5,\"mustread\":3,\"must-read\":3},\n",
    "    \n",
    "   ##############################\n",
    "   # Others :\n",
    "   ##############################\n",
    "    \"event\":{\n",
    "        \"webinar\":10,\"conference\":10,\"tedx\":5,\"symposium\":5,\"virtual session\":5,\n",
    "        \"virtual\": 1,\"session\": 1,\n",
    "        \"speaker\":4,\"hackathon\":4,\"meetup\":2,\"event\":2,\n",
    "        \"speech\":1,\"talk\":1,\"congres\":1,\"elevator pitch\":1,\"lecture\":1},\n",
    "    \"recruiting\":{\n",
    "        \"recruit\":15, \" hire\":15, \" hiring\":15, \"career\":8, \"resume\":8, \"cover letter\": 8,\n",
    "        \"salaries\":4, \"high pay\":4, \"interview\":3, \"job\":2, \"candidate\":2, 'role': 2,\n",
    "        \"intern \":2, \"application\":1, \"profile\":1, \"skill\":1}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_weights(text) :\n",
    "    text = text.lower()  \n",
    "    def _count(text, topic_name, topic_conf) :\n",
    "        return sum([weight for (kw,weight) in topic_conf.items() if kw in text])\n",
    "    w = {topic : _count(text, topic, conf) for (topic, conf) in manual_label_conf.items()}\n",
    "    return w\n",
    "df['topic_weights'] = df['text'].map(get_topic_weights)\n",
    "\n",
    "\n",
    "def sorting_weights(w) :\n",
    "    # Re-ordering by descending weights :\n",
    "    keys = np.array(list(w.keys()))\n",
    "    vals = np.array(list(w.values()))\n",
    "    argsort = np.argsort(-vals)\n",
    "    return {keys[i]:vals[i] for i in argsort}\n",
    "    \n",
    "df['topic_weights_sorted'] = df['topic_weights'].map(sorting_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['label']    = df['topic_weights_sorted'].map(lambda w: None if sum(w.values()) == 0 else list(w.keys())[0])\n",
    "df['label_w']  = df['topic_weights_sorted'].map(lambda w: None if sum(w.values()) == 0 else list(w.values())[0])\n",
    "df['label2_w'] = df['topic_weights_sorted'].map(lambda w: None if sum(w.values()) == 0 else list(w.values())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df, x='label_w', y='label2_w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['label'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Embedding using Neural Networks (Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = model.encode(df['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a t-SNE for vizualization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_label = np.vstack(df['topic_weights'].map(lambda w: np.array(list(w.values()))).values)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_label = scaler.fit_transform(X_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweeking of space :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded_2 = X_embedded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIZING DOWN clusters :\n",
    "conf_individuals = {\n",
    "     'application : industry (general)': 0.,\n",
    "     'application : covid19': 0.2,\n",
    "     'application : cybersecurity': 0.4,\n",
    "     'application : robotics': 0.4,\n",
    "     'application : finance': 0.2,\n",
    "     'application : climatology': 0.2,\n",
    "     'application : healthcare': 0.2,\n",
    "     'application : marketing': 0.2,\n",
    "     'application : astronomy': 0.4,\n",
    "     'application : nuclear': 0.4,\n",
    "     'application : cooking': 0.2,\n",
    "     'application : media & politics': 0.6,\n",
    "     'afghanistan': 0.4,\n",
    "     'cloud technologies': 0.4,\n",
    "     'implementation & tools': 0.4,\n",
    "     'maths': 0.4,\n",
    "     'devops': 0.4,\n",
    "     'dataviz': 0.4,\n",
    "     'deep learning': 0.,\n",
    "     'machine learning': 0.,\n",
    "     'AI': 0.,\n",
    "     'university/school': 0.45,\n",
    "     'training': 0.45,\n",
    "     'book': 0.4,\n",
    "     'event': 0.4,\n",
    "     'recruiting': 0.45}\n",
    "\n",
    "for topic, weight in conf_individuals.items() :\n",
    "    mask = (df['label']==topic).values\n",
    "    X_subset = X_embedded_2[mask,:]\n",
    "    average_coordinates = X_embedded_2[mask,:].mean(axis=0)\n",
    "    X_embedded_2[mask,:] = (1-weight)*X_embedded_2[mask,:] + weight*average_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVING SOME CLUSTER :\n",
    "conf_groups = {\n",
    "   \"applications_stay_together\":{\n",
    "      \"weight\":.4,\n",
    "      \"clusters_to_move\":[\n",
    "         \"application : covid19\",\n",
    "         \"application : cybersecurity\",\n",
    "         \"application : robotics\",\n",
    "         \"application : finance\",\n",
    "         \"application : climatology\",\n",
    "         \"application : healthcare\",\n",
    "         \"application : marketing\",\n",
    "         \"application : astronomy\",\n",
    "         \"application : nuclear\",\n",
    "         \"application : cooking\",\n",
    "         \"application : media & politics\",\n",
    "         \"application : industry (general)\",\n",
    "      ]\n",
    "   },\n",
    "    \n",
    "   \"applications_average\":{\n",
    "      \"weight\":.8,\n",
    "      \"clusters_to_move\":[\"application : industry (general)\"],\n",
    "      \"target\":[\n",
    "         \"application : covid19\",\n",
    "         \"application : cybersecurity\",\n",
    "         \"application : robotics\",\n",
    "         \"application : finance\",\n",
    "         \"application : climatology\",\n",
    "         \"application : healthcare\",\n",
    "         \"application : marketing\",\n",
    "         \"application : astronomy\",\n",
    "         \"application : nuclear\",\n",
    "         \"application : cooking\",\n",
    "         \"application : media & politics\",\n",
    "      ]\n",
    "   },\n",
    "    \n",
    "    \"health_application_should_stay_together\":{\n",
    "      \"weight\":.4,\n",
    "      \"clusters_to_move\":[\n",
    "          \"application : covid19\",\n",
    "          \"application : healthcare\",\n",
    "      ]\n",
    "   },\n",
    "#    \"ds_fields\":{\n",
    "#       \"weight\":.3,\n",
    "#       \"similar_topics\":[\n",
    "#          \"AI\",\n",
    "#          \"machine learning\",\n",
    "#          \"deep learning\"\n",
    "#       ]\n",
    "#    },\n",
    "   \"technos\":{\n",
    "      \"weight\":.1,\n",
    "      \"clusters_to_move\":[\n",
    "         \"cloud technologies\",\n",
    "         \"implementation & tools\",\n",
    "         \"devops\"\n",
    "      ]\n",
    "   },\n",
    "   \"learning\":{\n",
    "      \"weight\":.4,\n",
    "      \"clusters_to_move\":[\n",
    "         \"university/school\",\n",
    "         \"training\"\n",
    "      ]\n",
    "   }\n",
    "}\n",
    "\n",
    "for conf in conf_groups.values() :\n",
    "    clusters_to_move = conf['clusters_to_move']\n",
    "    weight = conf['weight']\n",
    "    # By default : Move clusters closer to each others :\n",
    "    target = conf['target'] if 'target' in conf.keys() else clusters_to_move\n",
    "    \n",
    "    target_mask = df['label'].isin(target).values\n",
    "    target_avg_coordinates = X_embedded_2[target_mask,:].mean(axis=0)\n",
    "    for clust in clusters_to_move :\n",
    "        clust_mask = (df['label'] == clust).values\n",
    "        clust_avg_coordinates = X_embedded_2[clust_mask,:].mean(axis=0)\n",
    "        moving_vector = weight * (target_avg_coordinates - clust_avg_coordinates)\n",
    "        X_embedded_2[clust_mask,:] += moving_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TSNE(n_components=3)\n",
    "# X_tsne = model.fit_transform(X_train)\n",
    "# df['tsne_0'] = X_tsne[:,0]\n",
    "# df['tsne_1'] = X_tsne[:,1]\n",
    "# df['tsne_2'] = X_tsne[:,2]\n",
    "# fig = px.scatter_3d(df.loc[~df['label'].isnull()], x='tsne_0', y='tsne_1', z='tsne_2', \n",
    "#                     color='label')\n",
    "# fig.update_traces(marker=dict(size=1))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a UMAP for vizualization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP(n_components=3)\n",
    "X_reduced = reducer.fit_transform(X_embedded_2)\n",
    "df['dim_0'] = X_reduced[:,0]\n",
    "df['dim_1'] = X_reduced[:,1]\n",
    "df['dim_2'] = X_reduced[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plotly.express.colors import find_intermediate_color \n",
    "# PURPLE = (100.,  0.,  100.)\n",
    "# BLUE   = (0.,    0.,  200.)\n",
    "# GREEN  = (0.,    200., 0.)\n",
    "# YELLOW = (100.,  100., 0.)\n",
    "# ORANGE = (150.,  50., 0.)\n",
    "# RED    = (200.,  0., 0.)\n",
    "\n",
    "# color_discrete_map={\n",
    "#     # GRAYS\n",
    "#     'cloud technologies':     (125., 125., 125.),\n",
    "#     'implementation & tools': (75.,  75.,  75.),\n",
    "#     'devops' :                (25.,  25.,  25.),\n",
    "    \n",
    "#     # PURPLE & BLUES\n",
    "#     'recruiting':          find_intermediate_color(PURPLE,BLUE,.25),\n",
    "#     'training':            find_intermediate_color(PURPLE,BLUE,.50),\n",
    "#     'book':                find_intermediate_color(PURPLE,BLUE,.75),\n",
    "#     'university/school':   BLUE,\n",
    "#     'event':               find_intermediate_color(BLUE,GREEN,.25),\n",
    "     \n",
    "#      # GREENS & YELLOWS\n",
    "#     'AI':                  find_intermediate_color(BLUE,GREEN,.50),\n",
    "#     'deep learning':       GREEN,\n",
    "#     'machine learning':    find_intermediate_color(GREEN, YELLOW, .60),\n",
    "#     'dataviz':             YELLOW,\n",
    "#     'maths':               find_intermediate_color(YELLOW,ORANGE,.15),\n",
    "    \n",
    "    \n",
    "#      # ORANGES & REDS\n",
    "#      # Red-Purple / Red / Red-Orange / Orange\n",
    "#     'application : media & politics':    find_intermediate_color(YELLOW,ORANGE,.50),\n",
    "#     'application : marketing':           find_intermediate_color(YELLOW,ORANGE,.75),\n",
    "#     'application : finance':             ORANGE,\n",
    "#     'application : healthcare':          find_intermediate_color(ORANGE,RED,1/5),\n",
    "#     'application : covid19':             find_intermediate_color(ORANGE,RED,2/5),\n",
    "#     'application : cooking':             find_intermediate_color(ORANGE,RED,3/5),\n",
    "#     'application : climatology':         find_intermediate_color(RED,PURPLE,4/5),\n",
    "#     'application : industry (general)':  RED,\n",
    "#     'application : astronomy':           find_intermediate_color(RED,PURPLE,1/6),\n",
    "#     'application : nuclear':             find_intermediate_color(RED,PURPLE,2/6),\n",
    "#     'application : cybersecurity':       find_intermediate_color(RED,PURPLE,3/6),\n",
    "#     'application : robotics':            find_intermediate_color(RED,PURPLE,4/6),\n",
    "#     'afghanistan':                       find_intermediate_color(RED,PURPLE,5/6),\n",
    "# }\n",
    "# color_discrete_map = {k:px.colors.label_rgb(v) for k,v in color_discrete_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df.loc[~df['label'].isnull()], x='dim_0', y='dim_1', z='dim_2', \n",
    "                    color='label', hover_name='text'\n",
    "#                     color_discrete_map=color_discrete_map\n",
    "                   )\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization with Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Topic applied to Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "filt = df['label'].isnull()\n",
    "\n",
    "topic_model = BERTopic() # int(sum(filt)/30)\n",
    "topics, _ = topic_model.fit_transform(df.loc[filt, 'text'].values)\n",
    "df['topic'] = None\n",
    "df.loc[filt, 'topic'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_overwrite = {\n",
    "#     '@teqipf is delivering' : 'university/school',\n",
    "#     'programming skills for data science (the r book)': 'book',\n",
    "#     'top 10 data science coding schools': 'university/school',\n",
    "#     'data science career': 'recruiting',\n",
    "#     'machine learning tutorial': 'hands-on training',\n",
    "#     'datascience certificates': 'online courses',\n",
    "#     'top 10 in-demand tech skills': 'training',\n",
    "#     'top 10 in-demand #techskills': 'training',\n",
    "#     'azure ml studio': 'cloud technologies',\n",
    "#     'vgpu': 'deep learning',\n",
    "#     'kickstart your career': 'recruiting',\n",
    "#     'postgrad conversion courses': 'university/school',\n",
    "#     'in partnership with @awscloud': 'cloud technologies',\n",
    "#     'businesses need to start upskilling': 'traininng',\n",
    "#     'now hiring': 'recruiting',\n",
    "#     'python vs r': 'implementation & tools',\n",
    "#     'python programming': 'implementation & tools',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['n_labels'] = df['manual_labels'].apply(lambda t: 0 if len(t) == 0 else len(t.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('n_labels', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('n_labels').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_overwrite(text) :\n",
    "    text = text.lower()\n",
    "    for k,v in manual_overwrite.items() :\n",
    "        if k in text :\n",
    "            return v\n",
    "df['manual_labels'] = df['text'].map(manual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
